[
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Our Course Project",
    "section": "",
    "text": "I’m honored to be a member of the [group name] project team.\nBelow, you’ll find a brief summary of our project. To access a detailed project description, please go to https://[https://emu-hacettepe-analytics.github.io/emu430-fall2023-team-team_safe_istanbul/l]\nSummary\n We will utilize three datasets provided by the Istanbul Metropolitan Municipality.\nThe first dataset, titled “Earthquake Scenario Analysis Results”, contains the outcomes of analyses conducted based on a 7.5 Mw nighttime earthquake scenario.\nThe second dataset, “Neighborhood-Based Building Numbers in 2017”, comprises information on the number of buildings in Istanbul’s neighborhoods. These buildings are categorized by their construction year and the number of floors.\nThe third dataset is “Municipality Population in 2019”, contains population of Istanbul by districts in 2019.\nOur objective is to compile a comprehensive report and identify the districts in Istanbul that are most susceptible to potential earthquakes. We aim to create an ordered priority list for neighborhoods and develop a risk map for Istanbul, taking geographical coordinates into account.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Analytics Lab",
    "section": "",
    "text": "Hello! My name is Taha Karakaya.\nThis is my personal webpage.\nStay tuned to follow my blog postings, data analytics projects, and more.\n\n\n\n Back to top"
  },
  {
    "objectID": "assignments/assignment-2.html",
    "href": "assignments/assignment-2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "Assignment 2\nImport Libraries and Data\n\nCode\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(stringr)\nlibrary(reshape2)\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(httr)\nlibrary(kableExtra)\n\nbase_url &lt;- \"https://www.imdb.com/search/title/?title_type=feature&num_votes=2500,&country_of_origin=TR&count=250\"\n\nurl_vector &lt;- c(\n  sprintf(\"%s&release_date=2010-01-01,2023-12-31\", base_url),\n  sprintf(\"%s&release_date=,2009-12-31\", base_url)\n)\n\nData Cleaning and Creating The Dataframe\n\n\nCode\nmovie_titles &lt;- c()\nmovie_years &lt;- c()\nmovie_durations &lt;- c()\nmovie_ratings &lt;- c()\nmovie_votes &lt;- c()\n\nfor(url in url_vector){\n  HTML = read_html(url)\n  \n  title_names &lt;- HTML %&gt;% html_nodes('.ipc-title__text')\n  title_names &lt;- html_text(title_names)\n  title_names &lt;- tail(head(title_names,-1),-1)\n  title_names &lt;- str_split(title_names, \" \", n=2)\n  title_names &lt;- unlist(lapply(title_names, function(x) {x[2]}))\n  \n  year &lt;- HTML %&gt;% html_nodes(\".sc-43986a27-7.dBkaPT.dli-title-metadata\")\n  year &lt;- html_text(year)\n  year &lt;- substr(year, 1, 4)\n  year &lt;- as.numeric(year)\n  \n  duration_trash &lt;- HTML %&gt;% html_nodes(\".sc-43986a27-7.dBkaPT.dli-title-metadata\")\n  duration_trash &lt;- html_text(duration_trash)\n  duration &lt;- c()\n  \n  for (string in duration_trash){\n  start_index &lt;- 5\n  string_length &lt;- str_length(string)\n\n  if(grepl(\"m\", string, fixed = TRUE)){\n    end_index &lt;- regexpr(\"m\", string)\n    result &lt;- substr(string, start_index, end_index)\n    duration &lt;- append(duration,result)\n    }\n    \n  else{\n    end_index &lt;- regexpr(\"h\", string)\n    result &lt;- substr(string, start_index, end_index)\n    duration &lt;- append(duration, result)\n    }\n  }\n    \n  \n  hour_duration &lt;- str_split(duration, \" \")\n  hour_duration &lt;- sapply(hour_duration, function(x) ifelse(grepl(\"h\", x[1], fixed = TRUE), x[1], 0))\n  hour_duration &lt;- sub(\"h\", \"\", hour_duration)\n  hour_duration &lt;- as.numeric(hour_duration)\n  hour_duration &lt;- hour_duration * 60\n  \n  minute_duration &lt;- str_split(duration, \" \")\n  minute_duration &lt;- sapply(minute_duration, function(x) ifelse(length(x) &gt;= 2, x[2], ifelse(grepl(\"m\", x, fixed = TRUE), x[1], ifelse(grepl(\"m\", x[1], fixed = TRUE), x[1],0))))\n  minute_duration &lt;- sub(\"m\", \"\", minute_duration)\n  minute_duration &lt;- as.numeric(minute_duration)\n  \n  rating &lt;- HTML %&gt;% html_nodes(\".ipc-rating-star.ipc-rating-star--base.ipc-rating-star--imdb.ratingGroup--imdb-rating\")\n  rating &lt;- html_text(rating)\n  rating &lt;- substr(rating, 1, 3)\n  rating &lt;- as.numeric(rating)\n  \n  vote &lt;- HTML %&gt;% html_nodes(\".sc-53c98e73-0.kRnqtn\")\n  vote &lt;- html_text(vote)\n  vote &lt;- sub(\"Votes\", \"\" ,vote)\n  vote &lt;- sub(\",\", \"\", vote)\n  vote &lt;- as.numeric(vote)\n  \n  movie_titles &lt;- append(movie_titles,title_names)\n  movie_years &lt;- append(movie_years, year)\n  movie_durations &lt;- append(movie_durations, hour_duration + minute_duration)\n  movie_ratings &lt;- append(movie_ratings, rating)\n  movie_votes &lt;- append(movie_votes, vote)\n  \n}\n\nmovies_df &lt;- data.frame(movie_titles, movie_years, movie_durations, movie_ratings, movie_votes)\nkable(head(movies_df,10), caption = \"Movies Dataframe\")\n\n\n\nMovies Dataframe\n\n\nmovie_titles\nmovie_years\nmovie_durations\nmovie_ratings\nmovie_votes\n\n\n\n\nKuru Otlar Üstüne\n2023\n197\n8.1\n5081\n\n\nIstanbul Için Son Çagri\n2023\n91\n5.3\n7376\n\n\nYedinci Kogustaki Mucize\n2019\n132\n8.2\n54161\n\n\nÖlümlü Dünya 2\n2023\n117\n7.5\n3472\n\n\nBihter\n2023\n113\n3.6\n3350\n\n\nÖlümlü Dünya\n2018\n107\n7.6\n30267\n\n\nKis Uykusu\n2014\n196\n8.0\n54642\n\n\nDag II\n2016\n135\n8.2\n109866\n\n\nDo Not Disturb\n2023\n114\n6.3\n8773\n\n\nAyla: The Daughter of War\n2017\n125\n8.3\n42991\n\n\n\n\n\n\n\nExamine the Structure of ‘movies_df’\n\n\nCode\nstr(movies_df)\n\n\n'data.frame':   470 obs. of  5 variables:\n $ movie_titles   : chr  \"Kuru Otlar Üstüne\" \"Istanbul Için Son Çagri\" \"Yedinci Kogustaki Mucize\" \"Ölümlü Dünya 2\" ...\n $ movie_years    : num  2023 2023 2019 2023 2023 ...\n $ movie_durations: num  197 91 132 117 113 107 196 135 114 125 ...\n $ movie_ratings  : num  8.1 5.3 8.2 7.5 3.6 7.6 8 8.2 6.3 8.3 ...\n $ movie_votes    : num  5081 7376 54161 3472 3350 ...\n\n\nTop 5 movies\n\n\nCode\ntop5_movies &lt;- head(movies_df[order(movies_df$movie_ratings, decreasing = TRUE), ], 5)\ntop5_movies\n\n\n                    movie_titles movie_years movie_durations movie_ratings\n257               Hababam Sinifi        1975              87           9.2\n39        CM101MMXI Fundamentals        2013             139           9.1\n273                   Tosun Pasa        1976              90           8.9\n337 Hababam Sinifi Sinifta Kaldi        1975              95           8.9\n321                Süt Kardesler        1976              80           8.8\n    movie_votes\n257       42513\n39        46996\n273       24329\n337       24370\n321       20888\n\n\nTo begin with, I saw every one of them except the “Süt Kardeşler”, and I think the ratings of Hababam Class film series and “Tosun Paşa” are very accurate. “Hababam Class” was a heartfelt and genuine film series, particularly in the way it represented the cultural norms of the time and its lovable character. Regarding “Fundamentals” I think it was among Cem Yılmaz’s greatest pieces, but after seeing some of his more recent works, I don’t feel a strong connection to the earlier ones. I disagree that it should be in second place because of this.\nWorst 5 movies\n\n\nCode\nbottom5_movies &lt;- head(movies_df[order(movies_df$movie_ratings), ], 5)\nbottom5_movies\n\n\n                      movie_titles movie_years movie_durations movie_ratings\n101 Cumali Ceber: Allah Seni Alsin        2017             100           1.0\n150                           Reis        2017             108           1.0\n189                 Cumali Ceber 2        2018             100           1.2\n199                          Müjde        2022              48           1.2\n245              15/07 Safak Vakti        2021              95           1.2\n    movie_votes\n101       39267\n150       73973\n189       10229\n199        9920\n245       20608\n\n\nIn fact, I haven’t watched any of them, and some of them I’ve never even heard of. However, even if I have to push myself, I’m considering seeing “Cumali Ceber: May God Take You” after this assignment is done :))\nMy best movies\n\n\nCode\nmy_movies &lt;- movies_df[movies_df$movie_titles %in% c(\"Gemide\", \"Av Mevsimi\", \"Kaybedenler Kulübü\"), ]\nmy_movies\n\n\n          movie_titles movie_years movie_durations movie_ratings movie_votes\n48  Kaybedenler Kulübü        2011             105           7.5       25128\n56          Av Mevsimi        2010             140           7.4       36262\n278             Gemide        1998             102           7.9       15722\n\n\nThis table leads me to believe that I don’t watch movies with ratings higher than eight. :)\nPlots\nScatter Plot of Average Ratings of Movies Over the Years\n\n\nCode\nmovies_df$movie_years &lt;- as.factor(movies_df$movie_years)\n\n# Calculate yearly rating averages\nrating_avg_by_year &lt;- movies_df %&gt;%\n  group_by(movie_years) %&gt;%\n  summarise(avg_rating = mean(movie_ratings),\n            num_movies = n())\n\n# Scatter plot of yearly rating averages with rotated year labels\nggplot(rating_avg_by_year, aes(x = movie_years, y = avg_rating)) +\n  geom_point() +\n  labs(title = \"Scatter Plot of Average Ratings of Turkish Movies Over the Years\",\n       x = \"Year\",\n       y = \"Average Rating\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))\n\n\n\n\n\nBox Plot of Ratings of Movies Over the Years\n\n\nCode\nggplot(movies_df, aes(x = movie_years, y = movie_ratings)) +\n  geom_boxplot() +\n  theme(axis.text.x = element_text(angle = 90, hjust=1)) +\n  labs(title = \"Box Plot of Ratings of Turkish Movies Over the Years\",\n       x = \"Year\",\n       y = \"Rating\")\n\n\n\n\n\nCorrelation between Votes and Ratings\n\n\nCode\nggplot(movies_df, aes(x = movie_votes, y = movie_ratings)) +\n  geom_point() +\n  labs(title = \"Scatter Plot of Votes vs Ratings\",\n       x = \"Number of Votes\",\n       y = \"Ratings\")\n\n\n\n\n\nNumerical Representation of the Above Graph (Correlation)\n\n\nCode\ncorrelation &lt;- cor(movies_df$movie_votes, movies_df$movie_ratings, use = \"complete.obs\")\n\ncat(\"Correlation between Votes and Ratings:\", correlation, \"\\n\")\n\n\nCorrelation between Votes and Ratings: 0.1307806 \n\n\nCorrelation between Duration and Ratings\n\n\nCode\ncorrelation_duration_rating &lt;- cor(movies_df$movie_durations, movies_df$movie_ratings, use = \"complete.obs\")\ncat(\"Correlation between Duration and Ratings:\", correlation_duration_rating, \"\\n\")\n\n\nCorrelation between Duration and Ratings: 0.03343216 \n\n\nCode\nggplot(movies_df, aes(x = movie_durations, y = movie_ratings)) +\n  geom_point() +\n  labs(title = \"Scatter Plot of Duration vs Ratings\",\n       x = \"Duration (minutes)\",\n       y = \"Ratings\")\n\n\n\n\n\nNumerical Representation of the Above Graph (Correlation)\n\n\nCode\ncorrelation_2 &lt;- cor(movies_df$movie_durations, movies_df$movie_ratings, use = \"complete.obs\")\n\ncat(\"Correlation between Duration and Ratings:\", correlation_2, \"\\n\")\n\n\nCorrelation between Duration and Ratings: 0.03343216 \n\n\nTurkish Movies in IMDb Top 1000\n\n\nCode\nURL_3 = \"https://www.imdb.com/search/title/?title_type=feature&groups=top_1000&country_of_origin=TR&count=250\"\n\nmovie_name &lt;- c()\nmovie_year &lt;- c()\n\nHTML &lt;- read_html(URL_3)\n\ntitle_names &lt;- HTML %&gt;% html_nodes('.ipc-title__text')\ntitle_names &lt;- html_text(title_names)\ntitle_names &lt;- tail(head(title_names, -1), -1)\ntitle_names &lt;- str_split(title_names, \" \", n = 2)\ntitle_names &lt;- unlist(lapply(title_names, function(x) x[2]))\n\nyear &lt;- HTML %&gt;% html_nodes(\".sc-43986a27-7.dBkaPT.dli-title-metadata\")\nyear &lt;- html_text(year)\nyear &lt;- substr(year, 1, 4)\nyear &lt;- as.numeric(year)\n\nmovie_name &lt;- append(movie_name, title_names)\nmovie_year &lt;- append(movie_year, year)\n\ntop1000_df &lt;- data.frame(movie_name, movie_year)\n\ntop1000_df %&gt;%\n  kable() %&gt;%\n  kable_styling(full_width = FALSE)\n\n\n\n\n\nmovie_name\nmovie_year\n\n\n\n\nYedinci Kogustaki Mucize\n2019\n\n\nKis Uykusu\n2014\n\n\nNefes: Vatan Sagolsun\n2009\n\n\nAyla: The Daughter of War\n2017\n\n\nBabam ve Oglum\n2005\n\n\nAhlat Agaci\n2018\n\n\nBir Zamanlar Anadolu'da\n2011\n\n\nEskiya\n1996\n\n\nG.O.R.A.\n2004\n\n\nVizontele\n2001\n\n\nHer Sey Çok Güzel Olacak\n1998\n\n\n\n\n\n\n\nMerging the Dataframe to Expand the other Columns\n\n\nCode\ntop1000_df_merged &lt;- merge(\n  x = top1000_df,\n  y = movies_df,\n  by.x = c(\"movie_name\", \"movie_year\"),\n  by.y = c(\"movie_titles\", \"movie_years\"),\n  all.x = TRUE\n)\n\ntop1000_df_merged %&gt;%\n  kable() %&gt;%\n  kable_styling(full_width = FALSE)\n\n\n\n\n\nmovie_name\nmovie_year\nmovie_durations\nmovie_ratings\nmovie_votes\n\n\n\n\nAhlat Agaci\n2018\n188\n8.0\n27011\n\n\nAyla: The Daughter of War\n2017\n125\n8.3\n42991\n\n\nBabam ve Oglum\n2005\n108\n8.2\n91035\n\n\nBir Zamanlar Anadolu'da\n2011\n157\n7.8\n49359\n\n\nEskiya\n1996\n128\n8.1\n71703\n\n\nG.O.R.A.\n2004\n127\n8.0\n66032\n\n\nHer Sey Çok Güzel Olacak\n1998\n107\n8.1\n27122\n\n\nKis Uykusu\n2014\n196\n8.0\n54642\n\n\nNefes: Vatan Sagolsun\n2009\n128\n8.0\n35020\n\n\nVizontele\n2001\n110\n8.0\n38402\n\n\nYedinci Kogustaki Mucize\n2019\n132\n8.2\n54161\n\n\n\n\n\n\n\nOrdered by Rankings\n\n\nCode\ntop1000_df_merged &lt;- top1000_df_merged[order(top1000_df_merged$movie_ratings, decreasing = TRUE),]\n\ntop1000_df_merged %&gt;%\n  kable() %&gt;%\n  kable_styling(full_width = FALSE)\n\n\n\n\n\n\nmovie_name\nmovie_year\nmovie_durations\nmovie_ratings\nmovie_votes\n\n\n\n\n2\nAyla: The Daughter of War\n2017\n125\n8.3\n42991\n\n\n3\nBabam ve Oglum\n2005\n108\n8.2\n91035\n\n\n11\nYedinci Kogustaki Mucize\n2019\n132\n8.2\n54161\n\n\n5\nEskiya\n1996\n128\n8.1\n71703\n\n\n7\nHer Sey Çok Güzel Olacak\n1998\n107\n8.1\n27122\n\n\n1\nAhlat Agaci\n2018\n188\n8.0\n27011\n\n\n6\nG.O.R.A.\n2004\n127\n8.0\n66032\n\n\n8\nKis Uykusu\n2014\n196\n8.0\n54642\n\n\n9\nNefes: Vatan Sagolsun\n2009\n128\n8.0\n35020\n\n\n10\nVizontele\n2001\n110\n8.0\n38402\n\n\n4\nBir Zamanlar Anadolu'da\n2011\n157\n7.8\n49359\n\n\n\n\n\n\n\nMovies Dataframe’s First 11, by ranking\n\n\nCode\nmovies_df %&gt;%\n  arrange(desc(movie_ratings)) %&gt;%\n  head(11) %&gt;%\n  kable(caption = \"First 11 Movies Sorted by Rating\") %&gt;%\n  kable_styling(full_width = FALSE)\n\n\n\nFirst 11 Movies Sorted by Rating\n\n\nmovie_titles\nmovie_years\nmovie_durations\nmovie_ratings\nmovie_votes\n\n\n\n\nHababam Sinifi\n1975\n87\n9.2\n42513\n\n\nCM101MMXI Fundamentals\n2013\n139\n9.1\n46996\n\n\nTosun Pasa\n1976\n90\n8.9\n24329\n\n\nHababam Sinifi Sinifta Kaldi\n1975\n95\n8.9\n24370\n\n\nSüt Kardesler\n1976\n80\n8.8\n20888\n\n\nSaban Oglu Saban\n1977\n90\n8.7\n18535\n\n\nZügürt Aga\n1985\n101\n8.7\n16135\n\n\nNeseli Günler\n1978\n95\n8.7\n11807\n\n\nKibar Feyzo\n1978\n83\n8.7\n17128\n\n\nHababam Sinifi Uyaniyor\n1976\n94\n8.7\n20640\n\n\nCanim Kardesim\n1973\n85\n8.6\n10097\n\n\n\n\n\n\n\nIt is obvious from the fact that no movie appears again in the two dataframes that IMDb considers other factors in addition to ratings when identifying the top 1000 films.\nIt’s also unexpected that the oldest film in the top 1000 was released in 1996 while the best movie_df movies are generally from the 80s.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "B.S., Industrial Engineering, Hacettepe University, Turkey, 2019 - Present\nErasmus+, Management and Economy, University of Lodz, Poland, 02.2022 - 07.2022"
  },
  {
    "objectID": "about.html#employements",
    "href": "about.html#employements",
    "title": "About Me",
    "section": "Employements",
    "text": "Employements\n\nFirm xxx, position xx, year xxx\nFirm yyy, position yyy, year yyy"
  },
  {
    "objectID": "about.html#internships",
    "href": "about.html#internships",
    "title": "About Me",
    "section": "Internships",
    "text": "Internships\n\nTurkish Aerospace Industries, Business Analyst Intern, Ankara, 07.2023 - 08.2023\nThe Ministry of Industry and Technology, Research Intern, Ankara, 08.2023 - 09.2023\nVispera Information Technologies, Data & Insight Analyst Intern, Remote, 09.2023 - 10.2023"
  },
  {
    "objectID": "assignments/assignment-1.html",
    "href": "assignments/assignment-1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "My first assignment has three parts."
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "My Assignments",
    "section": "",
    "text": "On this page, I showcase the assignment I conducted for the Fall 2023 EMU 430 Data Analytics course.\nPlease use left menu to navigate through my assignments.\nThe most recent update to this page was made on November 3, 2023\n\n\n\n Back to top"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Blog",
    "section": "",
    "text": "My Experiences in Erasmus from Medium\nMerhabalar! Öncelikle bu yazıyı okuyorsanız Erasmus’un ne demek olduğunu ve başınızdan geçmiş/geçecek olan süreçlere de aşinasınızdır diye düşünüyorum çünkü ben bunlardan bahsetmeyeceğim.\nBen bu yazımda size daha spesifik ve pratik bir bakış açısıyla gittiğim üniversiteden, kaldığım yurttan ve yaptığım gezilerden bilgi aktarmayı tercih ediyorum. Üstelik kendi Erasmus deneyimimden önce de madde madde yazılan deneyimleri okumayı daha elverişli bulduğumdan yazımın devamı da o şekilde olacak.\nEĞİTİM: Öncelikle Erasmus’a 2021–2022 bahar döneminde Polonya’nın Lodz şehrinde bulunan Lodz Üniversitesi’ne gittim. Lodz Üniversitesi bahar dönemini korona ne kadar etkisini yitirmiş olsa da online olarak devam ettirmeyi tercih etti. Toplam aldığım 5 ders vardı, kendi üniversitemde de yani Hacettepe Üniversitesi’nde de hepsini zorunlu seçmeli olarak eşleştirdim. 4 dersten de geçtim(geçemediğimi de hocanın işgüzarlığına veriyorum. Derslere girmiyordu…)\nGenel anlamıyla dersler çok rahat. Alıştığımız Türkiye şartlarından çok çok uzakta. Tek bir sınavları oluyor onda da gerçekten kalmak için adeta çaba göstermeniz gerekiyor. Derslerin de zaten hepsi İngilizce. Bu konuda Polonya’ya eğitim ve dersleri eşleyebilme açısından iyi bir puan veriyorum. Puanım: 9/10\nGENEL YAŞAM: Lodz eski sanayii kentiymiş bir zamanlar. Bu bakımdan gelişmiş bir şehirdi ama nereye kadar gelişmiş… Ankara’da doğup büyümüş biri olarak açıkçası bana yetersiz geldi bu durum. Yapılacak ciddi manada pek bir şey yoktu. Okul zaten dağınık bir kampüse sahip. Lodz da küçük bir şehir. Her kısmında bir fakülte var ki inanın Hacettepe Üniversitesi’ni seçmemin temel sebebi genel bir kampüsü olmasıydı. Bu yüzdendir sanırım, okulun spor faaliyetleri veya hobi olarak seçebileceğiniz bir topluluk bulmak oldukça zor. Erasmus grupları olmasa, akşam yapılacak aktivitelerimiz, yarışmalarımız dahi olmasa, yaşam gerçekten çok tekdüze.\nOnun dışında insanlar hakkında konuşacak olursam yaşıtımız olan, oranın yerlileri gayet sıcakkanlı, cana yakın. Çok da yardımlarını gördüm gerçekten, muazzam insanlar fakat diğer bir yandan 30+ yaş dediğimiz vakit Avrupa’nın genel olarak her yerinde karşılaştığım sıkıntıları burada da yaşadım. Dil anlama/konuşma yetersizliği, kendi milliyetinden olmayanı dışlama olmasa dahi gençler kadar cana yakın olmamaları. Bunu da kültüre bağlamak istiyorum. O kadar 5 ay kaldığım, insanıyla, yemeğiyle iç içe olduğum şehir hakkında kötü yorum yapmak istemiyorum. Genel anlamıyla havasıyla, insanıyla soğuk bir memleket. Onu da öyle kabul etmek lazım. Puanım: 7/10\nSEYAHAT: Gelelim en zevkli kısma ki bunu söylemekten büyük haz duyuyorum. Şu ekonomide, şu genel anlamıyla dünyanın enflasyon gibi lanet bir belayla karşı karşıya olduğu dönemde 12 ülke 25 şehirde bulundum fakat gezip tadına, kültürüne baktığım ise 10 ülke 18 şehir oldu. Herkesin hayalinde temel bir amaç oluyor Erasmus’a gelirken. Benimki de seyahatti. Avrupa’ya ilk çıkışımdı ve gerçekten de aklımda, zihnimde biriktirdiğim neresi varsa gittim. Hatta bazılarına ikişer üçer kez gittim orası da ayrı bir durum. Muhteşemdi. Barcelona’da denize girmek, Bologna gibi ‘Kızıl’ bir şehirde devrim niteliğinde bir Pride yürüyüşüne katılmak, Berlin’de tekno club denemeleri, Amterdam’da legal olan ne varsa deneyip farklı bir boyuta geçtiğimiz anlar, Roma’da her kuytu köşede espresso içmek(bir daha granül kahve içemedim o günden sonra…). İnanılmazdı. Tek kelimeyle… inanılmazdı.\nTabii her güzel şeyin bir olumsuz tarafı da oluyor. Gezdiğim, gördüğüm yerlerde ne kadar dikkat etsem dahi sırf aynı dili konuşmadığımdan ki çatpat İspanyolca bilirim, İngilizce’me de gerçekten güvenirim fakat yerel dili konuşmadığınız takdirde sanki ülkelerine baskın yapmaya gelen mülteci konumuna düşüyorsunuz ki emin olun bu hissin tam tersini bir bakıma hepimiz Türkiye’de hissetmişizdir. Bunun karşı tarafında olmak, üstelik öğrenim görmeye gittiğiniz, bilginizle, çabanızla gittiğiniz bir yerlerde bu durumla karşılaşmak acayip rahatsız edici bir durum. Bu da minik bir uyarı olarak burada kalsın, denk gelirseniz şaşırmayınız.\nGenel hatlarıyla seyahati de toparlayacak olursam Eyfel’e karşı sabahlamasından, trende, garda, havalimanında uyumasına kadar iyi-kötü tüm yönleriyle bana her dakika farklı bir şeyler katan bu konuya 10/10 vermek istiyorum. Bir daha olsa bir daha yaparım. Hayat kısa, görmek istediğiniz yerleri, deneyimlemek istediğiniz hayatları ertelemeyin. Kuş olun, uçun. Puanım 10/10\nÖZET: Polonya güzel bir ülke. Avrupa’da yaşamak da çok ayrı bir deneyim ancak gönül ister ki doğup büyüdüğüm yer de bu konumlarda olabilsin. Gerek ekonomisiyle gerek ifade özgürlüğüyle gerçek anlamda yaşadım, yaşadık diyebilelim. Atamızın ilkeleri önderliğinde, kendimiz geliştirmek için gerçekten çabalayalım. Biz bunu kendimiz yapmazsak kimse bizim için yapmayacak arkadaşlar. Kimse…\nSon olarak kazanamayanlara başka programların da olduğunu, onları da denemelerini; kazananlara ise bolca tebrik ve canıgönülden keyifli bir Erasmus geçirmelerini temenni ederim.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "assignments/assignment-1.html#a",
    "href": "assignments/assignment-1.html#a",
    "title": "Assignment 1",
    "section": "(a)",
    "text": "(a)\nIn that part, I watched a conference talk (https://www.rstudio.com/conference/2022/talks/develop-deploy-python-rstudio/) related to Model Building and Deployment in R.\nFirstly, I chose the conference talk because I thought that we could use R software language only to examine the data, make mathematical operations more understandable and faster. As I learned from the conference, we can perform not only these operations, but also more advanced operations.\nIn even more detail, they said that model building and model deployment processes can be even performed in R via programs like Workbench and Shiny.\nTo sum up, Workbench enables idle’s such as VSCode and Jupyter to work in integration with the R program, the Shiny program is used to report the output of the model in the web interface and to design an interactive web interface."
  },
  {
    "objectID": "assignments/assignment-1.html#b-3-differences-between-r-and-python-languages",
    "href": "assignments/assignment-1.html#b-3-differences-between-r-and-python-languages",
    "title": "Assignment 1",
    "section": "(b) 3 Differences between R and Python Languages",
    "text": "(b) 3 Differences between R and Python Languages\nThe biggest between them is creators. The constructors of the R programming language are statisticians, the constructors of Python are not.\n\n\nCode\n\n\n\n\n\nCode\n\n\n\nThe other difference is that Python is an Objected-Oriented Program but R is a Functional Programming Language.\nLast difference is that Python can run faster than R generally but R is optimized for statistical operations and can perform efficient operations on large data sets."
  },
  {
    "objectID": "assignments/assignment-1.html#c-dslabs-replacing-missing-values-to-0",
    "href": "assignments/assignment-1.html#c-dslabs-replacing-missing-values-to-0",
    "title": "Assignment 1",
    "section": "(c) dslabs, replacing missing values to 0",
    "text": "(c) dslabs, replacing missing values to 0\n\n\nCode\nlibrary(dslabs)\ndata(na_example)\nna_example\n\n\n   [1]  2  1  3  2  1  3  1  4  3  2  2 NA  2  2  1  4 NA  1  1  2  1  2  2  1\n  [25]  2  5 NA  2  2  3  1  2  4  1  1  1  4  5  2  3  4  1  2  4  1  1  2  1\n  [49]  5 NA NA NA  1  1  5  1  3  1 NA  4  4  7  3  2 NA NA  1 NA  4  1  2  2\n  [73]  3  2  1  2  2  4  3  4  2  3  1  3  2  1  1  1  3  1 NA  3  1  2  2  1\n  [97]  2  2  1  1  4  1  1  2  3  3  2  2  3  3  3  4  1  1  1  2 NA  4  3  4\n [121]  3  1  2  1 NA NA NA NA  1  5  1  2  1  3  5  3  2  2 NA NA NA NA  3  5\n [145]  3  1  1  4  2  4  3  3 NA  2  3  2  6 NA  1  1  2  2  1  3  1  1  5 NA\n [169] NA  2  4 NA  2  5  1  4  3  3 NA  4  3  1  4  1  1  3  1  1 NA NA  3  5\n [193]  2  2  2  3  1  2  2  3  2  1 NA  2 NA  1 NA NA  2  1  1 NA  3 NA  1  2\n [217]  2  1  3  2  2  1  1  2  3  1  1  1  4  3  4  2  2  1  4  1 NA  5  1  4\n [241] NA  3 NA NA  1  1  5  2  3  3  2  4 NA  3  2  5 NA  2  3  4  6  2  2  2\n [265] NA  2 NA  2 NA  3  3  2  2  4  3  1  4  2 NA  2  4 NA  6  2  3  1 NA  2\n [289]  2 NA  1  1  3  2  3  3  1 NA  1  4  2  1  1  3  2  1  2  3  1 NA  2  3\n [313]  3  2  1  2  3  5  5  1  2  3  3  1 NA NA  1  2  4 NA  2  1  1  1  3  2\n [337]  1  1  3  4 NA  1  2  1  1  3  3 NA  1  1  3  5  3  2  3  4  1  4  3  1\n [361] NA  2  1  2  2  1  2  2  6  1  2  4  5 NA  3  4  2  1  1  4  2  1  1  1\n [385]  1  2  1  4  4  1  3 NA  3  3 NA  2 NA  1  2  1  1  4  2  1  4  4 NA  1\n [409]  2 NA  3  2  2  2  1  4  3  6  1  2  3  1  3  2  2  2  1  1  3  2  1  1\n [433]  1  3  2  2 NA  4  4  4  1  1 NA  4  3 NA  1  3  1  3  2  4  2  2  2  3\n [457]  2  1  4  3 NA  1  4  3  1  3  2 NA  3 NA  1  3  1  4  1  1  1  2  4  3\n [481]  1  2  2  2  3  2  3  1  1 NA  3  2  1  1  2 NA  2  2  2  3  3  1  1  2\n [505] NA  1  2  1  1  3  3  1  3  1  1  1  1  1  2  5  1  1  2  2  1  1 NA  1\n [529]  4  1  2  4  1  3  2 NA  1  1 NA  2  1  1  4  2  3  3  1  5  3  1  1  2\n [553] NA  1  1  3  1  3  2  4 NA  2  3  2  1  2  1  1  1  2  2  3  1  5  2 NA\n [577]  2 NA  3  2  2  2  1  5  3  2  3  1 NA  3  1  2  2  2  1  2  2  4 NA  6\n [601]  1  2 NA  1  1  2  2  3 NA  3  2  3  3  4  2 NA  2 NA  4 NA  1  1  2  2\n [625]  3  1  1  1  3 NA  2  5 NA  7  1 NA  4  3  3  1 NA  1  1  1  1  3  2  4\n [649]  2  2  3 NA NA  1  4  3  2  2  2  3  2  4  2  2  4 NA NA NA  6  3  3  1\n [673]  4  4  2  1 NA  1  6 NA  3  3  2  1  1  6 NA  1  5  1 NA  2  6  2 NA  4\n [697]  1  3  1  2 NA  1  1  3  1  2  4  2  1  3  2  4  3  2  2  1  1  5  6  4\n [721]  2  2  2  2  4 NA  1  2  2  2  2  4  5 NA NA NA  4  3  3  3  2  4  2  4\n [745] NA NA NA NA  2  1 NA  2  4  3  2 NA  2  3  1  3  4 NA  1  2  1  2 NA  3\n [769]  1  2  1  2  1  2  1  2  2  2  2  1  1  3  3  1  3  4  3 NA NA  4  2  3\n [793]  2  1  3  2  4  2  2  3  1  2  4  3  3  4 NA  1  4  2  1  1  1  3  1  5\n [817]  2  2  4  2 NA  1  3  1  2 NA  1  2  1  2  1 NA  1  3  2  3  2 NA  2  1\n [841]  4  2 NA NA NA  2  4  2 NA NA  3  1 NA  5  5  2  2  2 NA  2  1  3  1  3\n [865]  2  4  2  4 NA  4  1  2  3  2  3  3  2  3  2  2  2  1  3  2  4  2 NA  3\n [889]  3  2  2 NA NA  3  2  1  2  4  1  1  1  1  4  3  2 NA  3  2 NA  1 NA  3\n [913]  2  1  1  1  2 NA  2  2  3  3  2 NA NA  4  5  2  2  2  1  2  3  1  3  3\n [937]  4  3 NA  1  1  1 NA  4  3  5  1  1  2 NA  2  2  2  2  5  2  2  3  1  2\n [961]  3 NA  1  2 NA NA  2 NA  3  1  1  2  5  3  5  1  1  4 NA  2  1  3  1  1\n [985]  2  4  3  3  3 NA  1  1  2  2  1  1  2  2 NA  2\n\n\n\n\nCode\ndata &lt;- na_example\ndata[is.na(data)] &lt;-0\ndata\n\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 0 2 2 1 4 0 1 1 2 1 2 2 1 2 5 0 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 0 0 0 1 1 5 1 3 1 0 4 4 7 3 2 0 0 1 0 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 0 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 0 4 3 4 3 1 2 1 0 0 0 0 1 5 1 2 1 3 5 3 2 2 0 0 0 0 3 5 3 1 1 4\n [149] 2 4 3 3 0 2 3 2 6 0 1 1 2 2 1 3 1 1 5 0 0 2 4 0 2 5 1 4 3 3 0 4 3 1 4 1 1\n [186] 3 1 1 0 0 3 5 2 2 2 3 1 2 2 3 2 1 0 2 0 1 0 0 2 1 1 0 3 0 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 0 5 1 4 0 3 0 0 1 1 5 2 3 3 2 4 0 3 2 5 0 2 3\n [260] 4 6 2 2 2 0 2 0 2 0 3 3 2 2 4 3 1 4 2 0 2 4 0 6 2 3 1 0 2 2 0 1 1 3 2 3 3\n [297] 1 0 1 4 2 1 1 3 2 1 2 3 1 0 2 3 3 2 1 2 3 5 5 1 2 3 3 1 0 0 1 2 4 0 2 1 1\n [334] 1 3 2 1 1 3 4 0 1 2 1 1 3 3 0 1 1 3 5 3 2 3 4 1 4 3 1 0 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 0 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 0 3 3 0 2 0 1 2 1 1 4 2 1 4 4 0\n [408] 1 2 0 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 0 4 4 4 1 1 0 4\n [445] 3 0 1 3 1 3 2 4 2 2 2 3 2 1 4 3 0 1 4 3 1 3 2 0 3 0 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 0 3 2 1 1 2 0 2 2 2 3 3 1 1 2 0 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 0 1 4 1 2 4 1 3 2 0 1 1 0 2 1 1 4 2 3 3 1 5 3 1 1 2 0 1 1\n [556] 3 1 3 2 4 0 2 3 2 1 2 1 1 1 2 2 3 1 5 2 0 2 0 3 2 2 2 1 5 3 2 3 1 0 3 1 2\n [593] 2 2 1 2 2 4 0 6 1 2 0 1 1 2 2 3 0 3 2 3 3 4 2 0 2 0 4 0 1 1 2 2 3 1 1 1 3\n [630] 0 2 5 0 7 1 0 4 3 3 1 0 1 1 1 1 3 2 4 2 2 3 0 0 1 4 3 2 2 2 3 2 4 2 2 4 0\n [667] 0 0 6 3 3 1 4 4 2 1 0 1 6 0 3 3 2 1 1 6 0 1 5 1 0 2 6 2 0 4 1 3 1 2 0 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 0 1 2 2 2 2 4 5 0 0 0 4 3 3 3\n [741] 2 4 2 4 0 0 0 0 2 1 0 2 4 3 2 0 2 3 1 3 4 0 1 2 1 2 0 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 0 0 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 0 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 0 1 3 1 2 0 1 2 1 2 1 0 1 3 2 3 2 0 2 1 4 2 0 0 0 2 4 2 0 0 3\n [852] 1 0 5 5 2 2 2 0 2 1 3 1 3 2 4 2 4 0 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 0 3\n [889] 3 2 2 0 0 3 2 1 2 4 1 1 1 1 4 3 2 0 3 2 0 1 0 3 2 1 1 1 2 0 2 2 3 3 2 0 0\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 0 1 1 1 0 4 3 5 1 1 2 0 2 2 2 2 5 2 2 3 1 2 3 0\n [963] 1 2 0 0 2 0 3 1 1 2 5 3 5 1 1 4 0 2 1 3 1 1 2 4 3 3 3 0 1 1 2 2 1 1 2 2 0\n[1000] 2"
  },
  {
    "objectID": "assignments/assignment-2.html#import-necessary-libraries",
    "href": "assignments/assignment-2.html#import-necessary-libraries",
    "title": "Assignment 2",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'rvest'\n\n\nThe following object is masked from 'package:readr':\n\n    guess_encoding\n\n\n\nAttaching package: 'reshape2'\n\n\nThe following object is masked from 'package:tidyr':\n\n    smiths"
  }
]